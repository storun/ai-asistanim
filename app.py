import streamlit as st
import os
from dotenv import load_dotenv
import tempfile

# --- GEREKLÄ° KÃœTÃœPHANELER ---
# Sohbet (Chat) iÃ§in Google Gemini
from langchain_google_genai import ChatGoogleGenerativeAI

# PDF'i SayÄ±sallaÅŸtÄ±rmak (Embedding) iÃ§in Ãœcretsiz Yerel Model (Kota dostu)
from langchain_community.embeddings import HuggingFaceEmbeddings

# VektÃ¶r VeritabanÄ± ve PDF YÃ¼kleyici
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

# 1. Ortam DeÄŸiÅŸkenlerini YÃ¼kle (.env dosyasÄ±nÄ± okur)
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# API AnahtarÄ± KontrolÃ¼
if not api_key:
    st.error("HATA: Google API AnahtarÄ± bulunamadÄ±! LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    st.stop()

# 2. Sayfa AyarlarÄ±
st.set_page_config(page_title="PDF AsistanÄ±", page_icon="ğŸ“š")
st.title("ğŸ“š PDF KitabÄ±nla Sohbet Et")

# 3. Yan MenÃ¼: Dosya YÃ¼kleme
st.sidebar.header("DÃ¶kÃ¼man YÃ¼kle")
uploaded_file = st.sidebar.file_uploader("Bir PDF dosyasÄ± yÃ¼kleyin", type="pdf")

# 4. Ana Ä°ÅŸlem Fonksiyonu
def pdf_isleme(file):
    # GeÃ§ici dosya oluÅŸtur (PyPDFLoader diskten okuma yapar)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(file.read())
        tmp_path = tmp_file.name

    # PDF'i YÃ¼kle ve ParÃ§ala
    loader = PyPDFLoader(tmp_path)
    documents = loader.load()
    
    # Metni kÃ¼Ã§Ã¼k parÃ§alara bÃ¶l (Chunking)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(documents)
    
    # --- KRÄ°TÄ°K NOKTA: Yerel Embedding Modeli ---
    # Google yerine bilgisayarÄ±n iÅŸlemcisini kullanÄ±r. Kota harcamaz.
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    
    # VektÃ¶r VeritabanÄ± OluÅŸtur
    db = Chroma.from_documents(texts, embeddings)
    
    # GeÃ§ici dosyayÄ± temizle
    os.remove(tmp_path)
    
    return db

# 5. Dosya YÃ¼klendiyse Ä°ÅŸlemleri BaÅŸlat
if uploaded_file is not None:
    with st.spinner("PDF analiz ediliyor, lÃ¼tfen bekleyin... (Ä°lk seferde model indirilebilir)"):
        try:
            # VeritabanÄ±nÄ± oluÅŸtur
            db = pdf_isleme(uploaded_file)
            st.success("PDF baÅŸarÄ±yla analiz edildi! SorularÄ±nÄ±zÄ± sorabilirsiniz.")
            
            # --- SOHBET MODELÄ°: Google Gemini ---
            llm = ChatGoogleGenerativeAI(
                model="models/gemini-2.5-flash-lite-preview-09-2025",
                temperature=0.3, 
                google_api_key=api_key
            )
            
            # Soru-Cevap Zincirini Kur
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=db.as_retriever()
            )
            
            # 6. KullanÄ±cÄ±dan Soru Al
            query = st.text_input("Kitapla ilgili sorunu yaz:")
            
            if query:
                with st.spinner("Cevap hazÄ±rlanÄ±yor..."):
                    response = qa_chain.invoke(query)
                    st.write("### ğŸ¤– Cevap:")
                    st.write(response["result"])
                    
        except Exception as e:
            st.error(f"Bir hata oluÅŸtu: {e}")

else:
    st.info("LÃ¼tfen sol menÃ¼den bir PDF dosyasÄ± yÃ¼kleyin.")