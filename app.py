import streamlit as st
import os
import tempfile
from dotenv import load_dotenv

# --- BAÅLANGIÃ‡ AYARLARI VE SQLITE YAMASI ---
# Streamlit Cloud'da ChromaDB hatasÄ±nÄ± Ã¶nlemek iÃ§in bu kÄ±sÄ±m ÅŸarttÄ±r.
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass
# -------------------------------------------

# --- KÃœTÃœPHANELER ---
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
# Import hatasÄ±nÄ± Ã¶nlemek iÃ§in daha gÃ¼venli bir yol:
from langchain.chains import RetrievalQA

# 1. API AnahtarÄ±nÄ± YÃ¼kle (Environment veya Secrets'tan)
load_dotenv()
# Streamlit Secrets kontrolÃ¼ (Bulutta Ã§alÄ±ÅŸÄ±rken burasÄ± devreye girer)
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.getenv("GOOGLE_API_KEY")

# 2. Sayfa AyarlarÄ±
st.set_page_config(page_title="PDF AsistanÄ±", page_icon="ğŸ¤–")
st.title("ğŸ“„ PDF Dosyanla Sohbet Et")

# 3. Embedding Modeli (Yerel & Ãœcretsiz - Kota Dostu)
@st.cache_resource # Modeli Ã¶nbelleÄŸe alarak hÄ±zlandÄ±rÄ±r
def get_embedding_model():
    return HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# 4. Dosya Ä°ÅŸleme Fonksiyonu
def process_pdf(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    loader = PyPDFLoader(tmp_path)
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(documents)

    embeddings = get_embedding_model()
    # ChromaDB'yi geÃ§ici bellekte Ã§alÄ±ÅŸtÄ±r
    db = Chroma.from_documents(texts, embeddings)
    
    os.remove(tmp_path)
    return db

# 5. ArayÃ¼z ve AkÄ±ÅŸ
st.sidebar.header("DÃ¶kÃ¼man YÃ¼kle")
uploaded_file = st.sidebar.file_uploader("PDF SeÃ§", type="pdf")

if uploaded_file:
    with st.spinner("PDF analiz ediliyor... (Ä°lk seferde model inebilir)"):
        try:
            db = process_pdf(uploaded_file)
            st.success("Analiz tamamlandÄ±! Sorunu sorabilirsin.")

            # --- SOHBET MODELÄ°: Google Gemini ---
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash", 
                temperature=0.3, 
                google_api_key=api_key
            )

            # Soru-Cevap Zinciri
            qa = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=db.as_retriever()
            )

            user_q = st.text_input("Soru:")
            if user_q:
                resp = qa.invoke(user_q)
                st.write("### ğŸ¤– Cevap:")
                st.write(resp["result"])

        except Exception as e:
            st.error(f"Hata oluÅŸtu: {e}")
else:
    st.info("LÃ¼tfen baÅŸlamak iÃ§in sol menÃ¼den bir PDF yÃ¼kleyin.")
